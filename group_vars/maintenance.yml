---
# MISC/Generic variables
hostname: "{{ inventory_hostname }}"
galaxy_root: /opt/galaxy
galaxy_venv_dir: "{{ galaxy_root }}/venv"
galaxy_server_dir: "{{ galaxy_root }}/server"
galaxy_config_dir: "{{ galaxy_root }}/config"
galaxy_config_file: "{{ galaxy_config_dir }}/galaxy.yml"
galaxy_mutable_config_dir: "{{ galaxy_root }}/mutable-config"
galaxy_log_dir: "/var/log/galaxy"

galaxy_group:
  name: galaxy
  gid: 999
galaxy_user:
  name: galaxy
  create_home: true
  home: /opt/galaxy
  uid: 999
  shell: /bin/bash

# Role: hxr.postgres-connection
# Role: usegalaxy-eu.galaxy-slurp
postgres_user: galaxy
postgres_host: sn11.galaxyproject.eu
postgres_port: 5432
pgc_users:
  - uname: "{{ galaxy_user.name }}"
    uhome: "{{ galaxy_user.home }}"
    gname: "{{ galaxy_group.name | default(galaxy_group) }}"
    pguser: "{{ postgres_user }}"
    pgpass: "{{ postgres_pass }}"
    pgdatabase: galaxy
  - uname: "{{ telegraf_user.name }}"
    uhome: "{{ telegraf_user.home }}"
    gname: "{{ telegraf_user.group }}"
    pguser: "{{ postgres_user }}"
    pgpass: "{{ postgres_pass }}"
    pgdatabase: galaxy

# Role: usegalaxy_eu.handy.os_setup
enable_hostname: true
enable_powertools: true
enable_remap_user: true
enable_exclude_packages: true
enable_pam_limits: true
enable_install_software: true
enable_create_user: true
software_groups_to_install:
  - admin
  - debug
  - editors
  - pdf_export_deps
  - services
  - terminals
  - utils
handy_users:
  - user_name: "{{ galaxy_user.name }}"
    user_uid: "{{ galaxy_user.uid }}"
    user_group: "{{ galaxy_group.name }}"
    user_comment: "Galaxy useraccount"
    user_create_home: "{{ galaxy_user.create_home }}"
    user_home: "{{ galaxy_user.home }}"
    user_shell: "{{ galaxy_user.shell }}"
handy_groups:
  - group_name: "{{ galaxy_group.name }}"
    group_gid: "{{ galaxy_group.gid }}"

# Role: usegalaxy-eu.autofs
# Appending additional mounts to autofs_conf_files variable (var file: mounts/dest/all.yml)
# This mounts the galaxy sync directory from the NFS server to /opt/galaxy
galaxy_mount:
  - "{{ sync.gxkey.path }}     -{{ sync.gxkey.nfs_options | join(',') }}      {{ sync.gxkey.export }}"

autofs_service:
  install: true
  enable: true
nfs_kernel_tuning: true
autofs_mount_points:
  - data
  - gxtest
  - gxkey
  - jwd
  - usrlocal
  - cache
  - misc

# Role: usegalaxy-eu.bashrc
galaxy_pulsar_app_conf: "{{ galaxy_config_dir }}/pulsar_app.yml"
bashrc_users:
  - uname: "{{ galaxy_user.name }}"
    uhome: "{{ galaxy_user.home }}"
    gname: "{{ galaxy_group.name }}"

# Role: usegalaxy_eu.fs_maintenance
fsm_maintenance_dir: "/data/dnb01/maintenance"
fsm_intervals:
  short: "3d"
  medium: "7d"
  long: "31d"
fsm_scripts:
  temporary_dirs:
    enable: true
    src: "temporary_dirs.sh.j2"
    dst: "{{ fsm_maintenance_dir }}/temporary_dirs.sh"
    user: "{{ fsm_galaxy_user.username }}"
    group: "{{ fsm_galaxy_user.groupname }}"
    paths:
      - /data/dnb-ds03/galaxy_db/tmp
      - /data/dnb05/galaxy_db/tmp
      - /data/dnb06/galaxy_db/tmp
      - "{{ generic_tmp_dir }}"
      - "{{ short_term_web_storage_dir }}"
      - "{{ object_store_cache_dir }}"
    time: "{{ fsm_intervals.long }}"
  upload_dirs:
    enable: true
    src: "uploads.sh.j2"
    dst: "{{ fsm_maintenance_dir }}/uploads.sh"
    user: "{{ fsm_galaxy_user.username }}"
    group: "{{ fsm_galaxy_user.groupname }}"
    paths:
      - "{{ galaxy_config['galaxy']['nginx_upload_store'] }}"
      - "{{ galaxy_config['galaxy']['nginx_upload_job_files_store'] }}"
      - "{{ upload_dir_main }}"
      - "{{ upload_dir_test }}"
    time: "{{ fsm_intervals.medium }}"
  job_working_dirs:
    enable: true
    src: "job_working_dir.sh.j2"
    dst: "{{ fsm_maintenance_dir }}/job_working_dir.sh"
    user: "{{ fsm_galaxy_user.username }}"
    group: "{{ fsm_galaxy_user.groupname }}"
    paths:
      - "{{ galaxy_config['galaxy']['job_working_directory'] }}"
      - /data/dnb-ds03/galaxy_db/job_working_directory
      - /data/jwd/main
      - /data/jwd01/main
      - /data/jwd02f/main
      - /data/jwd03f/main
      - /data/jwd04/main
      - /data/jwd05e/main
      - /data/jwd06/main
      - /data/jwd07/main
    time: "{{ fsm_intervals.long }}"
fsm_htcondor_enable: true

# Role: dj-wasabi.telegraf
telegraf_agent_metric_buffer_limit: 100000
telegraf_agent_hostname: "{{ hostname }}"
telegraf_agent_version: 1.17.2
custom_telegraf_env: "/usr/bin/env GDPR_MODE=1 PGUSER={{ galaxy_user.name }} PGHOST={{ postgres_host }} GALAXY_ROOT={{ galaxy_server_dir }} GALAXY_CONFIG_FILE={{ galaxy_config_file }} GXADMIN_PYTHON={{ galaxy_venv_dir }}/bin/python"
# When GDPR_MODE is set for the Telegraf ENV the galaxy_num_anonymous_jobs_by_destination.sh script returns empty. When this is enabled, gxadmin masks the user details, which is non-existent for anonymous users, leading to empty results.
custom_telegraf_env_without_gdpr_mode: "/usr/bin/env PGUSER={{ galaxy_user.name }} PGHOST={{ postgres_host }} GALAXY_ROOT={{ galaxy_server_dir }} GALAXY_CONFIG_FILE={{ galaxy_config_file }} GXADMIN_PYTHON={{ galaxy_venv_dir }}/bin/python"
telegraf_plugins_extra:
  postgres:
    plugin: "postgresql"
    config:
      - address = "{{ galaxy_db_connection }}"
      - databases = ["galaxy", "galaxy-test", "apollo", "chado"]
  monitor_nfsstat:
    plugin: "exec"
    config:
      - commands = ["/usr/bin/nfsstat-influx"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "15s"
  galaxy_uploaded:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery upload-gb-in-past-hour"]
      - timeout = "600s"
      - data_format = "influx"
      - interval = "1h"
  galaxy_jobs_queued:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery jobs-queued"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_jobs_queued_internal:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery jobs-queued-internal-by-handler"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_jobs_queue_overview:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery queue-overview --short-tool-id"]
      - timeout = "30s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_jobs_destination_overview:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery queue --by destination"]
      - timeout = "30s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_oidc:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery users-with-oidc"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_workflow:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery workflow-invocation-status"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_workflow_totals:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery workflow-invocation-totals"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_tool_usage:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_tool_usage"]
      - timeout = "360s"
      - data_format = "influx"
      - interval = "24h"
  galaxy_tool_usage_over_time:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_tool_usage_over_time"]
      - timeout = "360s"
      - data_format = "influx"
      - interval = "24h"
  galaxy_job_queue_states_stats:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_job_queue_states_stats"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_jobs_per_handler_stats:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_jobs_per_handler_stats"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  monitor_condor_queue:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-queue"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"
  monitor_condor_util:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-utilisation"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"
  monitor_condor_util_split:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-utilisation-split"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"
  monitor_condor_queue_jobs:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-queue-jobs"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"
  postgres_extra:
    plugin: "exec"
    config:
      - commands = [
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-cache-hit",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-index-size",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-index-usage",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-table-bloat",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-table-size",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-unused-indexes",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-vacuum-stats",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-stat-bgwriter",
        "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-stat-user-tables",
        ]
      - timeout = "60s"
      - data_format = "influx"
      - interval = "2m"
  galaxy_destination_queue_run_time: # This is used for the TPV Broker.
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery destination-queue-run-time --seconds --older-than=90"]
      - timeout = "30m"
      - data_format = "influx"
      - interval = "24h"
  galaxy_job_radar_visualization_stats:
    plugin: "exec"
    config:
      - commands = [
        "{{ custom_telegraf_env }} /usr/bin/galaxy_failed_jobs_by_destination.sh",
        "{{ custom_telegraf_env }} /usr/bin/galaxy_most_used_tools_by_destination.sh",
        "{{ custom_telegraf_env_without_gdpr_mode }} /usr/bin/galaxy_num_anonymous_jobs_by_destination.sh",
        "{{ custom_telegraf_env }} /usr/bin/galaxy_unique_users_job_count_by_destination.sh",
        "{{ custom_telegraf_env }} /usr/bin/galaxy_longest_running_jobs_by_destination.sh",
        "{{ custom_telegraf_env }} /usr/bin/galaxy_num_user_running_jobs_count_by_destination.sh",
        ]
      - timeout = "300s"
      - data_format = "influx"
      - interval = "1h"
  galaxy_job_radar_visualization_job_stats:
    plugin: "exec"
    config:
      - commands = [
        "{{ custom_telegraf_env }} /usr/bin/galaxy_jobs_stats.sh",
        ]
      - timeout = "60s"
      - data_format = "influx"
      - interval = "4h"
  galaxy_monthly_active_users:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_monthly_active_users"]
      - timeout = "600s"
      - data_format = "influx"
      - interval = "168h"
  galaxy_user_file_source_utilisation:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_user_file_source_utilisation"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "24h"
  galaxy_user_object_store_utilisation:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/galaxy_user_object_store_utilisation"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "24h"
  galaxy_wizard_openai_utilization_and_costs:
    plugin: "exec"
    config:
      - commands = ['bash -c "source {{ telegraf_user.home }}/.bashrc && {{ custom_telegraf_env }} /usr/bin/galaxy_wizard_openai_utilization_and_costs.py"']
      - timeout = "120s"
      - data_format = "influx"
      - interval = "24h"

# Role: hxr.monitor-cluster
monitor_condor: true

# Role: usegalaxy-eu.dynmotd
dynmotd_custom:
  - name: Condor
    command: "condor_q -totals | tail -n 2"

# Role: usegalaxy-eu.galaxy-slurp
galaxy_slurper: galaxy
galaxy_slurp_influx_pass: "{{ influxdb.node.password }}"
galaxy_slurp_influx_user: "{{ influxdb.node.username }}"
galaxy_slurp_influx_url: "{{ influxdb.url }}"

# Role: galaxyproject.gxadmin
gxadmin_commit: main
gxadmin_dir: /opt/gxadmin
gxadmin_bin_dir: /usr/bin
gxadmin_force: true

# Role: usegalaxy-eu.logrotate
lp_logrotate_confd:
  - path: rsyslog
    conf: |
      /var/log/remote/*/*.log {
        weekly
        rotate 5
        missingok
        dateext
        notifempty
        compress
      }

# WallE
walle_verbose: false
walle_script_location: /usr/local/sbin/walle.py
walle_delete_threshold: HIGH
walle_delete_users: false
walle_filesize_min: 0
walle_tool: interactive
walle_user_name: "{{ galaxy_user.name }}"
walle_user_group: "{{ galaxy_group.name }}"
walle_virtualenv: "{{ galaxy_venv_dir }}"
walle_bashrc: "{{ galaxy_user.home }}/.bashrc"
walle_pgpass_file: "{{ galaxy_user.home }}/.pgpass"
walle_malware_database_location: "/data/dnb01/maintenance/walle"
walle_database_file: checksums.yml
walle_galaxy_url: "https://usegalaxy.eu"
walle_api_key: "{{ admin_api_key_maintenance }}"
walle_extra_env_vars:
  PGHOST: sn11.galaxyproject.eu
  WALLE_USER_DELETION_MESSAGE: >-
      Our systems have detected activity related to your Galaxy account that most likely violate our terms of service.
      To prevent damage and in accordance with our terms of service, we automatically deleted your account.
      This means your jobs were terminated and you can not login anymore.
      However it is possible to restore the account and its data.
      If you think your account was deleted due to an error, please contact contact@usegalaxy.eu
walle_envs_database:
  MALWARE_LIB: "{{ walle_malware_database_location }}/{{ walle_database_file }}"
  PGPASSFILE: "{{ walle_pgpass_file }}"
  PGUSER: galaxy
  PGDATABASE: galaxy
  GXADMIN_PATH: /usr/local/bin/gxadmin
walle_cron_day: "*"
walle_cron_hour: "*"
walle_cron_minute: "0"

# Restics
restic_schedule_type: "cronjob"
restic_user: galaxy
restic_repos:
  local:
    location: "/data/dnb01/mutable-data"
    password: {{ restic_password }}
    init: false
restic_backups:
  data:
    name: mutable-data
    repo: local
    src: /opt/galaxy/mutable-data/
    scheduled: true
    schedule_hour: "21"
    schedule_minute: "0"
    keep_last: 15
    prune: true
